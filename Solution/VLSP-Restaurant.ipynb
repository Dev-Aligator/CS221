{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2918daee-553c-410c-b11e-ed446922ffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 23:27:29.061168: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-08 23:27:29.120509: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 23:27:29.358877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-08 23:27:29.358905: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-08 23:27:29.360397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-08 23:27:29.501851: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-08 23:27:29.504355: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-08 23:27:30.487302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving speedtest.net configuration...\n",
      "Testing from VNPT (113.161.73.9)...\n",
      "Retrieving speedtest.net server list...\n",
      "Selecting best server based on ping...\n",
      "Hosted by FPT Telecom (Ho Chi Minh City) [9.23 km]: 14.879 ms\n",
      "Testing download speed................................................................................\n",
      "Download: 11.14 Mbit/s\n",
      "Testing upload speed......................................................................................................\n",
      "Upload: 9.42 Mbit/s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "!curl -s https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py | python -\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dd97531-3142-487d-a22d-56882311d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'VLSP2018-SA-train-dev-test/csv/train.csv'\n",
    "VAL_PATH = 'VLSP2018-SA-train-dev-test/csv/dev.csv'\n",
    "TEST_PATH = 'VLSP2018-SA-train-dev-test/csv/test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccebe6d4-e8b3-4a56-ae30-5a8d3f39d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (2961,) y.shape: (2961, 12)\n",
      "X.shape: (1290,) y.shape: (1290, 12)\n",
      "X.shape: (500,) y.shape: (500, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def read_csv(url):\n",
    "    df = pd.read_csv(url)\n",
    "\n",
    "    X = df.pop('review')\n",
    "    y = df.replace({np.nan: 0, \n",
    "                    'negative': 1, \n",
    "                    'neutral': 2, \n",
    "                    'positive': 3}).astype(np.uint8)\n",
    "\n",
    "    print('X.shape:', X.shape, 'y.shape:', y.shape)\n",
    "    return X, y\n",
    "\n",
    "Xtrain, ytrain = read_csv(TRAIN_PATH)\n",
    "Xdev,   ydev   = read_csv(VAL_PATH)\n",
    "Xtest,  ytest  = read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702f634b-6bc1-441f-9a6a-3719dc47a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import demoji\n",
    "from flashtext import KeywordProcessor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import unicodedata\n",
    "\n",
    "HASHTAG = 'hashtag'\n",
    "\n",
    "class TextCleanerBase(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create preprocessing function\n",
    "        self.normalize_unicode = partial(unicodedata.normalize, 'NFC')\n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.Series):\n",
    "            X = pd.Series(X)\n",
    "\n",
    "        return X.apply(str.lower) \\\n",
    "                .apply(remove_emojis) \\\n",
    "                .apply(self.normalize_unicode)\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9a46a4-b38d-4134-a13f-5ba9d4e69a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = ['FOOD#PRICES',\n",
    "           'FOOD#QUALITY',\n",
    "           'FOOD#STYLE&OPTIONS',\n",
    "           'DRINKS#PRICES',\n",
    "           'DRINKS#QUALITY',\n",
    "           'DRINKS#STYLE&OPTIONS',\n",
    "           'RESTAURANT#PRICES',\n",
    "           'RESTAURANT#GENERAL',\n",
    "           'RESTAURANT#MISCELLANEOUS',\n",
    "           'SERVICE#GENERAL',\n",
    "           'AMBIENCE#GENERAL',\n",
    "           'LOCATION#GENERAL']\n",
    "\n",
    "sentiments = ['-', 'o', '+']\n",
    "\n",
    "def mo2ml(y):\n",
    "    \"\"\"Convert multi-output to multi-label data\n",
    "    \"\"\"\n",
    "    newcols = [f'{a} {s}' for a in aspects for s in sentiments]\n",
    "\n",
    "    nrows, ncols = len(y), len(newcols)\n",
    "    ml = pd.DataFrame(np.zeros((nrows, ncols), dtype='bool'),\n",
    "                      columns=newcols)\n",
    "    \n",
    "    for i, a in enumerate(aspects):\n",
    "        for j in range(1, 4):\n",
    "            indices = y[a] == j\n",
    "            ml.iloc[indices, i * 3 + j - 1] = True\n",
    "\n",
    "    return ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea90ebb3-2866-4f5a-bd83-1503da76992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mo2df(y):\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        return y\n",
    "    return pd.DataFrame(y, columns=aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4360977-0989-4729-afd8-9b1fb361eae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       _ ảnh chụp từ hôm qua, đi chơi với gia đình và...\n",
       "1       _hương vị thơm ngon, ăn cay cay rất thích, nêm...\n",
       "2       - 1 bàn tiệc hoành tráng 3 đứa ăn no muốn tắt ...\n",
       "3       - các bạn nhìn cái chảo này có to không - trên...\n",
       "4       - cháo: có nhiều hương cho các bạn chọn, nhưng...\n",
       "                              ...                        \n",
       "2956                                 y hệt vị đà lạt luôn\n",
       "2957    yaourt trái cây mát lạnh, có thêm viên kem ở t...\n",
       "2958               zumi.... zumi lễ vẫn bán nhé mọi người\n",
       "2959    set này có 2 tầng bánh và 1 ấm trà mà chỉ có 1...\n",
       "2960    lạnh trời thế này mà ngồi ăn chả cá lăng xèo x...\n",
       "Name: review, Length: 2961, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_base  = TextCleanerBase()\n",
    "\n",
    "xtrain_basecl = cleaner_base.transform(Xtrain)\n",
    "xdev_basecl   = cleaner_base.transform(Xdev)\n",
    "xtest_basecl  = cleaner_base.transform(Xtest)\n",
    "\n",
    "ytrain_b  = ytrain.copy()\n",
    "ydev_b    = ydev  .copy()\n",
    "ytest_b   = ytest .copy()\n",
    "\n",
    "ytrain_ml = mo2ml(ytrain)\n",
    "ydev_ml   = mo2ml(ydev)\n",
    "ytest_ml  = mo2ml(ytest)\n",
    "\n",
    "xtrain_basecl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272a9de4-d8e0-455a-af70-0613c44ef5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                             min_df=2, max_df=0.9)\n",
    "\n",
    "# x data using basic clean up class and basic features extrator\n",
    "xtrain_basecl_basef = vectorizer.fit_transform(xtrain_basecl)\n",
    "xdev_basecl_basef   = vectorizer.transform(xdev_basecl)\n",
    "xtest_basecl_basef  = vectorizer.transform(xtest_basecl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b713168-ba43-4ae9-bab8-4370caefa48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "\n",
    "def quick_f1(y_true, y_pred):\n",
    "    y_pred = mo2ml(mo2df(y_pred))\n",
    "    return round(f1_score(y_true, y_pred, average='micro', zero_division=0), 4)\n",
    "\n",
    "def evaluate(model, X, y, average='micro'):\n",
    "    yb_true  = mo2ml(y)\n",
    "\n",
    "    yb_pred  = mo2df(model.predict(X))\n",
    "    yb_pred  = mo2ml(yb_pred)\n",
    "\n",
    "    return classification_report(yb_true, yb_pred, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf7732e-57f2-4a2a-a7a0-84266eb75b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aligator/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2023-10-08 23:28:12,843] A new study created in memory with name: no-name-d91e8dce-0c08-463f-ba11-cb92da3a70a4\n",
      "[I 2023-10-08 23:28:17,202] Trial 0 finished with value: 0.6548 and parameters: {'class_weight': None, 'C': 8.41076650090714}. Best is trial 0 with value: 0.6548.\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-10-08 23:28:30,084] Trial 1 finished with value: 0.5823 and parameters: {'class_weight': 'balanced', 'C': 6.777285823434402}. Best is trial 0 with value: 0.6548.\n",
      "[I 2023-10-08 23:28:32,985] Trial 2 finished with value: 0.6528 and parameters: {'class_weight': None, 'C': 4.408098128709346}. Best is trial 0 with value: 0.6548.\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-10-08 23:28:42,468] Trial 3 finished with value: 0.6617 and parameters: {'class_weight': 'balanced', 'C': 11.224078321223027}. Best is trial 3 with value: 0.6617.\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aligator/.local/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2023-10-08 23:28:55,664] Trial 4 finished with value: 0.5887 and parameters: {'class_weight': 'balanced', 'C': 3.7822352140976876}. Best is trial 3 with value: 0.6617.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.21      0.29        28\n",
      "           1       0.54      0.53      0.53       175\n",
      "           2       0.47      0.63      0.54       128\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.49      0.47      0.48        43\n",
      "           5       0.88      0.93      0.91       403\n",
      "           6       1.00      0.06      0.12        16\n",
      "           7       0.22      0.04      0.06        53\n",
      "           8       0.74      0.95      0.83       334\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.50      0.09      0.15        45\n",
      "          11       0.25      0.07      0.11        28\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.56      0.41      0.47        54\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.53      0.59      0.56        41\n",
      "          18       0.00      0.00      0.00         5\n",
      "          19       0.50      0.08      0.14        24\n",
      "          20       0.29      0.34      0.31        44\n",
      "          21       1.00      0.08      0.14        13\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.52      0.84      0.64       205\n",
      "          24       0.33      0.11      0.17         9\n",
      "          25       0.00      0.00      0.00        62\n",
      "          26       0.75      0.05      0.10        59\n",
      "          27       0.44      0.16      0.24        25\n",
      "          28       0.60      0.14      0.22        22\n",
      "          29       0.56      0.78      0.65       128\n",
      "          30       0.33      0.12      0.17        26\n",
      "          31       0.18      0.08      0.11        48\n",
      "          32       0.76      0.82      0.79       181\n",
      "          33       0.50      0.31      0.38        16\n",
      "          34       0.70      0.33      0.45        99\n",
      "          35       0.54      0.34      0.42        64\n",
      "\n",
      "   micro avg       0.65      0.60      0.62      2419\n",
      "   macro avg       0.41      0.27      0.28      2419\n",
      "weighted avg       0.60      0.60      0.57      2419\n",
      " samples avg       0.65      0.61      0.62      2419\n",
      "\n",
      "train: 0.9991\n",
      "dev:   0.6617\n",
      "test: 0.6241\n",
      "{'C': 11.224078321223027, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 5, 'solver': 'sag', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "{'class_weight': 'balanced', 'C': 11.224078321223027}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.multioutput import MultiOutputClassifier as MOC\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key='best_model', value=trial.user_attrs['model'])\n",
    "\n",
    "def logistic_objective(trial):\n",
    "    params = dict(\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        C=trial.suggest_float('C', 1e-5, 20),\n",
    "        random_state=5,\n",
    "    )    \n",
    "\n",
    "    clf = MOC(LogisticRegression(solver='sag', max_iter=200, **params))\n",
    "    clf.fit(xtrain_basecl_basef, ytrain_b)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(xdev_basecl_basef)\n",
    "    return quick_f1(ydev_ml, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "logistic_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "logistic_study.optimize(logistic_objective, n_trials=5, callbacks=[callback])\n",
    "\n",
    "\n",
    "clf4 = logistic_study.user_attrs['best_model']\n",
    "\n",
    "print(evaluate(clf4, xtest_basecl_basef, ytest_b))\n",
    "\n",
    "print('train:', quick_f1(ytrain_ml, clf4.predict(xtrain_basecl_basef)))\n",
    "print('dev:  ', quick_f1(ydev_ml  , clf4.predict(xdev_basecl_basef)))\n",
    "print('test:', quick_f1(ytest_ml  , clf4.predict(xtest_basecl_basef)))\n",
    "\n",
    "print(clf4.estimators_[0].get_params())\n",
    "print(logistic_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b501d6c-5619-4dc5-a504-9e85f679e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = [\n",
    "   'Quán này mình biết cũng khá lâu rồi, lâu lâu cũng hay ghé ăn lắm, mà lần nào lại thấy cũng đông nghẹt. Nằm trong khu chung cư nên không gian rất thích, tuy bàn chủ yếu ở ngoài trời nhưng không bị khói bụi, rất mát mẻ, thích hợp ngồi ăn uống tám chuyện buổi tối lắm, chắc vì vậy mà mấy bạn trẻ ghé đây ăn rất nhiều. Đặc biệt món súp cua ở đây khá hot, tới trễ là hết liền. Bữa mình đi tính ăn, mới hơn 7h vậy mà lại hết sạch :(  Hết súp cua nên kêu mì ốc với bánh flan ăn nè  Mì xào ốc tỏi - 45k   Mì ở đây là mì gói thì phải, ăn sợi mì cũng bình thường nhưng nêm nếm rất ngon, có tỏi cháy làm rất thơm ngon, mùi vị đậm đà, khỏi chan nước mắm vô nghen.  Ốc tỏi xắt miếng nhỏ, ăn thấy tươi và ngon, nhưng thấy hơi ít. Giá này thấy cũng hơi mắc nghen!  Bánh flan kêu 2 phần flan thường với flan rau câu dừa - 10k/dĩa   Bánh flan ở đây không có nhiều loại, chỉ có nhiêu đây hà   Phần rau câu dừa này có flan với cái dừa bên trong nha, ăn vừa dai dai sật sật, vừa béo thơm ngon lắm  Flan ở đây làm cũng ngon lắm nè, bánh ăn béo mịn, ngọt vừa phải, làm theo kiểu truyền thống thôi nên không có đủ loại, và chỉ rưới cà phê lên chứ cũng không có topping gì hết nhưng mình ăn thấy thích lắm  Không gian bên ngoài nè, nằm bên mé chung cư  Ở giữa là bãi cỏ công viên nên không khí khá mát mẻ và trong lành, bàn kê ra khắp nơi, nhằm khi để cả lên cỏ',\n",
    "]\n",
    "text = vectorizer.transform(test_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e035c2b5-a2fb-4b9e-8dc9-f9b85e06f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04809804, 0.1004057 , 0.76526105, 0.08623521]]),\n",
       " array([[0.00561806, 0.00952508, 0.16233857, 0.82251829]]),\n",
       " array([[0.02285304, 0.04970076, 0.07852333, 0.84892287]]),\n",
       " array([[0.78947172, 0.01868046, 0.11601795, 0.07582988]]),\n",
       " array([[0.72580452, 0.00627059, 0.03864078, 0.22928411]]),\n",
       " array([[7.49719304e-01, 2.50261839e-03, 1.03865657e-04, 2.47674212e-01]]),\n",
       " array([[0.76936978, 0.03075209, 0.08141528, 0.11846284]]),\n",
       " array([[0.07298189, 0.01261912, 0.02712856, 0.88727043]]),\n",
       " array([[0.87847046, 0.07623925, 0.03264614, 0.01264414]]),\n",
       " array([[0.38973684, 0.13927879, 0.20793398, 0.26305039]]),\n",
       " array([[0.07102182, 0.07911105, 0.31715705, 0.53271008]]),\n",
       " array([[0.50098124, 0.07774878, 0.09138668, 0.32988331]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.predict_proba(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ffe33e5-6be1-4925-9fe1-d664db4d316c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pipe.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib\n",
    "\n",
    "pipe = make_pipeline(TextCleanerBase(), vectorizer, clf4)\n",
    "joblib.dump(pipe, 'pipe.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96934ba-90bc-4d2d-92e4-b4b409477f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
